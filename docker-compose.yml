version: '3.8'

services:
  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: chatbot-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - chatbot-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3



  # User Service
  user-service:
    build:
      context: ./user-service
      dockerfile: Dockerfile
    container_name: chatbot-user-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3001
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-here}
      - SUPABASE_URL=${USER_SUPABASE_URL:-your-user-supabase-url}
      - SUPABASE_ANON_KEY=${USER_SUPABASE_ANON_KEY:-your-user-supabase-key}
      - REDIS_URL=redis://redis:6379
    networks:
      - chatbot-network
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Chat Service (có thể scale nhiều instance)
  chat-service:
    build:
      context: ./chat-service
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3004
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-here}
      - SUPABASE_URL=${CHAT_SUPABASE_URL:-your-chat-supabase-url}
      - SUPABASE_ANON_KEY=${CHAT_SUPABASE_ANON_KEY:-your-chat-supabase-key}
      - USER_SERVICE_URL=http://user-service:3001
      - REDIS_URL=redis://redis:6379
      - CLUSTER_WORKERS=2  # Tối ưu cho container: 2 workers per instance
      - GEMINI_API_KEY=${GEMINI_API_KEY:-your-gemini-key}
    networks:
      - chatbot-network
    depends_on:
      user-service:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      replicas: 3 # Tăng lên 3 instances để xử lý load
      resources:
        limits:
          memory: 1024M  # Tăng memory limit
          cpus: '2.0'    # Tăng CPU limit
        reservations:
          memory: 512M   # Tăng memory reservation
          cpus: '1.0'    # Tăng CPU reservation

  # Voice Service
  voice-service:
    build:
      context: ./voice-service
      dockerfile: Dockerfile
    # Removed container_name to allow scaling
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3005
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-here}
      - SUPABASE_URL=${SUPABASE_URL:-your-supabase-url}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY:-your-supabase-key}
      - USER_SERVICE_URL=http://user-service:3001
    networks:
      - chatbot-network
    depends_on:
      - user-service
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.8'
        reservations:
          memory: 256M
          cpus: '0.4'

  # API Gateway
  api-gateway:
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    # Removed container_name to allow scaling
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3000
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-here}
      - USER_SERVICE_URL=http://user-service:3001
      - CHAT_SERVICE_URL=http://chat-service:3004
      - VOICE_SERVICE_URL=http://voice-service:3005
      - REDIS_URL=redis://redis:6379
    networks:
      - chatbot-network
    depends_on:
      - user-service
      - chat-service
      - voice-service
      - redis
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Frontend
  frontend:
    build:
      context: ./frontend-chatbot-1
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=http://localhost:8080
    # Removed container_name to allow scaling
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:8080
    networks:
      - chatbot-network
    depends_on:
      - api-gateway
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    container_name: chatbot-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # API Gateway
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - chatbot-network
    depends_on:
      - frontend
      - api-gateway
      - chat-service
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

networks:
  chatbot-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  redis_data:
    driver: local
